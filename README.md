# Journi Analytics Warehouse (SPARK)

![CI](https://github.com/juanenciso/journi-analytics-warehouse/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/Python-3.9-blue)
![Apache Spark](https://img.shields.io/badge/Spark-3.5-orange)
![License](https://img.shields.io/badge/License-MIT-green)


End-to-end **local analytics warehouse** built with **PySpark**, following a **Bronze â†’ Silver** lakehouse pattern, including **data quality checks, automated tests**, and CI with **GitHub Actions**.

This project simulates a real-world analytics setup where raw product, marketing, and user data is transformed into reliable, decision-ready datasets.

# ğŸš€ Project Overview

The goal of this project is to demonstrate how to:

Build a **scalable analytics pipeline** using Apache Spark

Transform heterogeneous raw data into **clean, structured analytical tables**

Add **data quality (DQ) metrics** to ensure trust in reporting

Automate execution with a **Makefile**

Validate outputs with **pytest**

Run everything automatically in **CI**

The project is designed to run **locally** but mirrors patterns used in production analytics platforms.

# ğŸ— Architecture
```
Raw Data
  â”‚
  â–¼
Bronze Layer (raw parquet)
  â”‚
  â–¼
Silver Layer (cleaned, modeled tables)
  â”‚
  â”œâ”€ users
  â”œâ”€ orders
  â”œâ”€ events
  â””â”€ ads
  â”‚
  â–¼
Data Quality Report (JSON Lines)
```
# Data Layers

- **Bronze**: raw ingested parquet data

- **Silver**: cleaned, typed, analytics-ready tables

- **DQ Report**: per-table metrics (row counts, null rates, duplicates)


# ğŸ“ Project Structure
```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generate_data.py      # Synthetic data generation
â”‚   â”œâ”€â”€ spark_session.py      # Spark session config
â”‚   â””â”€â”€ etl/
â”‚       â”œâ”€â”€ bronze.py         # Bronze layer ETL
â”‚       â””â”€â”€ silver.py         # Silver layer + DQ checks
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_silver_dq.py     # Data quality smoke tests
â”‚
â”œâ”€â”€ warehouse/               # Generated by pipeline (gitignored)
â”‚   â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ silver/
â”‚       â””â”€â”€ dq_report/
â”‚
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

# ğŸ§ª Data Quality Metrics
For each Silver table, the pipeline computes:

- **Row count**

- **Maximum null rate across columns**

- **Duplicate rate** on primary identifiers (when applicable)

Example `(dq_report)`:

```bash
{"table":"users","rows":500000,"null_rate_max":0.001,"dup_rate_id":0.0}
{"table":"orders","rows":2000000,"null_rate_max":0.0,"dup_rate_id":0.0}
{"table":"events","rows":10000000,"null_rate_max":0.0,"dup_rate_id":0.0}
{"table":"ads","rows":2000000,"null_rate_max":0.0,"dup_rate_id":-1.0}
```

# âš™ï¸ How to Run

1ï¸âƒ£ Setup environment

```bash
make venv
make install
```
2ï¸âƒ£ Run full pipeline

```bash
make all
```
3ï¸âƒ£ Run tests

```bash
make test
```

4ï¸âƒ£ Clean outputs

```bash
make clean
```
# ğŸ¤– Continuous Integration

The project includes a **GitHub Actions CI workflow** that automatically:

-Sets up Python and Java 17

-Builds the virtual environment

-Runs the full Spark pipeline

-Executes all tests

-Every push and pull request is validated automatically.

# ğŸ§  Key Skills Demonstrated

-Apache Spark (PySpark)

-Analytics engineering (Bronze / Silver layers)

-Data quality monitoring

-Scalable ETL design

-Python testing with pytest

-CI/CD with GitHub Actions

-Reproducible local environments


# ğŸ“Œ Why This Project

This project reflects real challenges faced by analytics teams:

Turning messy data into **trusted insights**

Making pipelines **observable and testable**

Ensuring data quality before it reaches dashboards or stakeholders

It is intentionally designed to be **simple, readable, and production-oriented**.



ğŸ‘¤ Author

Juan Enciso
Senior Data Scientist / Data Analyst

Tech: Python, PySpark, Apache Spark, Data Quality, ETL, GitHub Actions, pytest

